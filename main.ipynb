{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Hugging Face movie review sentiment classification with distilbert model with TensorFlow\n",
    "\n",
    "The main purpose of this excercise is to make use of Hugging Face resources to train a model with TensorFlow, to study the implementation details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, TFDistilBertModel\n",
    "from tensorflow.keras import layers, models\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"ajaykarthick/imdb-movie-reviews\")\n",
    "train_data_raw = data['train']['review']\n",
    "train_labels = data['train']['label']\n",
    "test_data_raw = data['test']['review']\n",
    "test_labels = data['test']['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "10000\n",
      "[\"Ms Aparna Sen, the maker of Mr & Mrs Iyer, directs this movie about a young girl's struggle to cope with her debilitating condition.<br /><br />Meethi (Konkona Sen) has been an aloof kid ever since childhood and has shown signs of delusion, no one knows why. The dormant tendency however slips out of control, when the job assignment takes her to neighboring Bihar where she's raped by some political goons. The resulting trauma also leads to episodes of manic-depressive psychosis in addition to her schizophrenia. She careens out of control over the years, progressively getting worse and sinking deeper into her private 'world'.<br /><br />The juxtaposition of an 'unsettled' (divorced) elder sister and how her domineering ways make an already bad situation worse, is indicative of what a fine line there is between abnormal and *seemingly normal*. Ms Sen also makes an excellent commentary on the social alienation of such individuals. Social rehab is standard therapy along with all the deadly mind-altering drugs. But what about the poor and the destitute, who're always left to fend for themselves and usually fall by the wayside?<br /><br />The romantic connection between Dr Kunal and Anu was unnecessary. Also the cafeteria scene where Dr Kunal explains to Anu how real their world really is to them, was redundant. Anu should already know all that. The English dialog is a bit awkward at times though the acting compensates for that. Konkona and Shabana prove that their reputation is every bit worth it. Waheeda, Rahul and Shefali play their limited roles very well. <br /><br />Extensive research seems to have been done about this illness, its very evident. But its not clear if MDP can coexist with schizophrenia in the same patient, side-by-side. Also in the early part, Dr Kunal recommends E.C.T (shock therapy) while invalidating the fact that it doesn't work for schizophrenics, only for extreme MDP with suicidal tendencies and other forms of bipolar disorder.<br /><br />The ending of the remarkable story is suggestive of an unknown solution (maybe no solution). The movie could have ended on a nicer note, since worldwide the mentally ill can and do lead balanced and fruitful if not very fulfilling, lives under good medical care.<br /><br />Nonetheless, its an excellent film made with extreme sensitivity to the subject. HATS OFF to Ms Sen! No one in India could've done it better.\", \"I have seen this film only once, on TV, and it has not been repeated. This is strange when you consider the rubbish that is repeated over and over again. Usually horror movies for me are a source of amusement, but this one really scared me.<br /><br />DO NOT READ THE NEXT BIT IF YOU HAVE'NT SEEN THE FILM YET<br /><br />The scariest bit is when the townsfolk pursue the preacher to where his wife lies almost dead (they'd been poisoning her). He asks who the hell are you people anyway. One by one they give their true identities. The girl who was pretending to be deaf in order to corrupt and seduce him says 'I am Lilith, the witch who loved Adam before Eve'.\", \"I was only fourteen when I first saw the Alien movies and I immediately came to like it. Original, terrifying and classic. Sigourney Weaver was the perfect choice for the female hero character and she would have deserved a statuette for her act. In 1979 something everlasting was born than the immortal series continued with a nothing less legendary movie than the first. Alien3 was a different point of view but I think this part was the most stressful and unique of all, this was my favourite. Unfortunately the last one was a failure in many ways. It was strained, illogical with full of meaningless massacres. I didn't like it at all, but I never thought that a worse part would ever be made in the future. Well as it turned out in 2004 I was wrong. Alien vs. Predator was a bad break, and it should have been directed by a more talented director or should have never been made at all. But when I saw Alien vs Predator Requiem I was totally shocked moreover devastated. When I sat down and decided to watch it with full of doubt, even than I had never thought that such a bad movie could be made. Without a screenplay, without a director and without actors I don't understand how can a film be made. Because this film misses these three terms. What you get is a nice massacre show without a story but with a lot of annoying and boring dialogues. Waste of money and waste of time. This movie is rather impudence, than honor to the fans of the both sides (Alien/Predator). Shame!\"]\n",
      "[0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data_raw))\n",
    "print(len(test_data_raw))\n",
    "print(train_data_raw[0:3])\n",
    "print(train_labels[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilbert/distilbert-base-uncased')\n",
    "\n",
    "def tokenize(texts):\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512, # TODO: 512\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "\n",
    "train_data_raw = tokenize(train_data_raw)\n",
    "test_data_raw = tokenize(test_data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Encoding(num_tokens=512, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data_raw))\n",
    "print(train_data_raw[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(40000, 512), dtype=int32, numpy=\n",
       "array([[ 101, 5796, 9706, ..., 2064, 1998,  102],\n",
       "       [ 101, 1045, 2031, ...,    0,    0,    0],\n",
       "       [ 101, 1045, 2001, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 101, 1037, 3522, ..., 4962, 4938,  102],\n",
       "       [ 101, 7619, 2442, ...,    0,    0,    0],\n",
       "       [ 101, 2023, 2003, ...,    0,    0,    0]])>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMPORTANT: check out tokenized data from the dataset\n",
    "# it is stored in the field 'input_ids'\n",
    "train_data_raw['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices(\n",
    "  (\n",
    "    train_data_raw['input_ids'],\n",
    "    train_labels\n",
    "  )\n",
    ").batch(32)\n",
    "\n",
    "test_data = tf.data.Dataset.from_tensor_slices(\n",
    "  (\n",
    "    test_data_raw['input_ids'],\n",
    "    test_labels\n",
    "  )\n",
    ").batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 512), dtype=tf.int32, name=None),\n",
       " TensorSpec(shape=(None,), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# FIXME:\n",
    "# There are some warnings in the output cells: \"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel\"\n",
    "# distilbert_model = TFDistilBertModel.from_pretrained('distilbert/distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 512)]             0         \n",
      "                                                                 \n",
      " distilbert_base_layer_7 (Di  (None, 768)              66362880  \n",
      " stilbertBaseLayer)                                              \n",
      "                                                                 \n",
      " dropout_140 (Dropout)       (None, 768)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 769       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,363,649\n",
      "Trainable params: 769\n",
      "Non-trainable params: 66,362,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class DistilbertBaseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, trainable: bool = True, **kwargs):\n",
    "        super(DistilbertBaseLayer, self).__init__(**kwargs)\n",
    "        # There are some warnings in the output cells: \"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel\"\n",
    "        self.distilbert_model = TFDistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.distilbert_model.trainable = trainable\n",
    "    def call(self, inputs):\n",
    "        return self.distilbert_model(inputs)[0][:, 0, :]\n",
    "\n",
    "def create_model0(trainable: bool = True):\n",
    "    inputs = tf.keras.Input(shape=512, dtype=tf.int32)\n",
    "    x = inputs\n",
    "    x = DistilbertBaseLayer(trainable)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    model0 = create_model0(trainable=False)\n",
    "    model0.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model0.summary()\n",
    "\n",
    "# For Windows, a warning about developer mode is displayed. Please turn it on if you want to use symlinks.\n",
    "# https://learn.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "125/125 [==============================] - 392s 3s/step - loss: 0.7255 - accuracy: 0.5178 - val_loss: 0.6924 - val_accuracy: 0.5202 - lr: 1.0000e-04\n",
      "Epoch 2/5\n",
      "125/125 [==============================] - 391s 3s/step - loss: 0.7100 - accuracy: 0.5365 - val_loss: 0.6746 - val_accuracy: 0.6199 - lr: 3.1623e-04\n",
      "Epoch 3/5\n",
      "125/125 [==============================] - 389s 3s/step - loss: 0.6740 - accuracy: 0.5792 - val_loss: 0.6358 - val_accuracy: 0.7126 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "125/125 [==============================] - 389s 3s/step - loss: 0.6125 - accuracy: 0.6745 - val_loss: 0.5647 - val_accuracy: 0.7644 - lr: 0.0032\n",
      "Epoch 5/5\n",
      "125/125 [==============================] - 391s 3s/step - loss: 0.5721 - accuracy: 0.6992 - val_loss: 0.4889 - val_accuracy: 0.7837 - lr: 0.0100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This training is to find the optimal learning rate for the model\n",
    "\n",
    "history0 = model0.fit(\n",
    "  train_data,\n",
    "  steps_per_epoch=round(0.1 * len(train_data)),\n",
    "  epochs=5,\n",
    "  validation_data=test_data,\n",
    "  validation_steps=round(0.5 * len(test_data)),\n",
    "  callbacks=[\n",
    "    tf.keras.callbacks.LearningRateScheduler(\n",
    "      lambda epoch: 10 ** (-4 + epoch * 0.5) # from 0.0001 to 0.01\n",
    "    )\n",
    "  ]\n",
    ")\n",
    "\n",
    "pd.DataFrame(history0.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m     model0 \u001b[38;5;241m=\u001b[39m create_model0(trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m     model0\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 8\u001b[0m history0 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m  \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m  \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m  \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m  \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m  \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(history0\u001b[38;5;241m.\u001b[39mhistory)\u001b[38;5;241m.\u001b[39mplot()\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:963\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    961\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[0;32m    962\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 963\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    965\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[0;32m    966\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[0;32m    967\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:785\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 785\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_get_concrete_function_internal_garbage_collected(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    786\u001b[0m         \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    789\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2983\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2981\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2982\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 2983\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2984\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3292\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3288\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[0;32m   3289\u001b[0m       args, kwargs, flat_args, filtered_flat_args)\n\u001b[0;32m   3291\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd_call_context(cache_key\u001b[38;5;241m.\u001b[39mcall_context)\n\u001b[1;32m-> 3292\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[0;32m   3294\u001b[0m                          graph_function)\n\u001b[0;32m   3296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3130\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3125\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3126\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   3127\u001b[0m ]\n\u001b[0;32m   3128\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   3129\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 3130\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3133\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3135\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3138\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3139\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   3141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   3142\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   3143\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   3144\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   3145\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   3146\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   3147\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   3148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1161\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1159\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1161\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1163\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[0;32m   1166\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:677\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    674\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    675\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    676\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 677\u001b[0m     out \u001b[38;5;241m=\u001b[39m weak_wrapped_fn()\u001b[38;5;241m.\u001b[39m__wrapped__(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    678\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1136\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1136\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1137\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filewrja5e_7.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py:1010\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1007\u001b[0m   run_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[0;32m   1008\u001b[0m       run_step, jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, experimental_relax_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1009\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1010\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1011\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1012\u001b[0m     outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1312\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m   1308\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1310\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[0;32m   1311\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 1312\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2888\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2886\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   2887\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m-> 2888\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3689\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   3688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m-> 3689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py:1000\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    999\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1000\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1001\u001b[0m   \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py:863\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[0;32m    862\u001b[0m \u001b[38;5;66;03m# Run backwards pass.\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:530\u001b[0m, in \u001b[0;36mOptimizerV2.minimize\u001b[1;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mminimize\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss, var_list, grad_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    500\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[0;32m    501\u001b[0m \n\u001b[0;32m    502\u001b[0m \u001b[38;5;124;03m  This method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    528\u001b[0m \n\u001b[0;32m    529\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 530\u001b[0m   grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_gradients\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m      \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    532\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_gradients(grads_and_vars, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:583\u001b[0m, in \u001b[0;36mOptimizerV2._compute_gradients\u001b[1;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[0;32m    581\u001b[0m var_list \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(var_list)\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/gradients\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 583\u001b[0m   grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assert_valid_dtypes([\n\u001b[0;32m    586\u001b[0m     v \u001b[38;5;28;01mfor\u001b[39;00m g, v \u001b[38;5;129;01min\u001b[39;00m grads_and_vars\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m g \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m v\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m tf\u001b[38;5;241m.\u001b[39mresource\n\u001b[0;32m    588\u001b[0m ])\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grads_and_vars\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:464\u001b[0m, in \u001b[0;36mOptimizerV2._get_gradients\u001b[1;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, tape, loss, var_list, grad_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    463\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 464\u001b[0m   grads \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    465\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, var_list))\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1081\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1077\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_gradients \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1078\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1079\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mflatten(output_gradients)]\n\u001b[1;32m-> 1081\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[43mimperative_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[0;32m   1090\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:156\u001b[0m, in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    154\u001b[0m     gradient_name_scope \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m forward_pass_name_scope \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmock_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1893\u001b[0m, in \u001b[0;36m_BatchMatMulV2\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1891\u001b[0m sx \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mshape(x)\n\u001b[0;32m   1892\u001b[0m sy \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mshape(y)\n\u001b[1;32m-> 1893\u001b[0m rx, ry \u001b[38;5;241m=\u001b[39m \u001b[43mgen_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_gradient_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43msx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msy\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1894\u001b[0m grad_x \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mreshape(math_ops\u001b[38;5;241m.\u001b[39mreduce_sum(grad_x, rx), sx)\n\u001b[0;32m   1895\u001b[0m grad_y \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mreshape(math_ops\u001b[38;5;241m.\u001b[39mreduce_sum(grad_y, ry), sy)\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:770\u001b[0m, in \u001b[0;36mbroadcast_gradient_args\u001b[1;34m(s0, s1, name)\u001b[0m\n\u001b[0;32m    768\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m--> 770\u001b[0m _, _, _op, _outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_op_def_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBroadcastGradientArgs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    772\u001b[0m _result \u001b[38;5;241m=\u001b[39m _outputs[:]\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:740\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    735\u001b[0m must_colocate_inputs \u001b[38;5;241m=\u001b[39m [val \u001b[38;5;28;01mfor\u001b[39;00m arg, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(op_def\u001b[38;5;241m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    736\u001b[0m                         \u001b[38;5;28;01mif\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mis_ref]\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    738\u001b[0m   \u001b[38;5;66;03m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    739\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 740\u001b[0m   op \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_type_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    741\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    742\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattr_protos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    744\u001b[0m \u001b[38;5;66;03m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    745\u001b[0m \u001b[38;5;66;03m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;66;03m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# for more details.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m outputs \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39moutputs\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:693\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    691\u001b[0m   inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcapture(inp)\n\u001b[0;32m    692\u001b[0m   captured_inputs\u001b[38;5;241m.\u001b[39mappend(inp)\n\u001b[1;32m--> 693\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFuncGraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3776\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3773\u001b[0m \u001b[38;5;66;03m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3774\u001b[0m \u001b[38;5;66;03m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3776\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3777\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3778\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3779\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3780\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3781\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcontrol_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrol_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3782\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3783\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_original_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3784\u001b[0m \u001b[43m      \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3785\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_op_helper(ret, compute_device\u001b[38;5;241m=\u001b[39mcompute_device)\n\u001b[0;32m   3786\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2171\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2169\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m op_def \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2170\u001b[0m     op_def \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39m_get_op_def(node_def\u001b[38;5;241m.\u001b[39mop)\n\u001b[1;32m-> 2171\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_c_op \u001b[38;5;241m=\u001b[39m \u001b[43m_create_c_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2172\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcontrol_input_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2173\u001b[0m   name \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_str(node_def\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   2175\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_traceback \u001b[38;5;241m=\u001b[39m tf_stack\u001b[38;5;241m.\u001b[39mextract_stack_for_node(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_c_op)\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1983\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1981\u001b[0m inputs \u001b[38;5;241m=\u001b[39m _reconstruct_sequence_inputs(op_def, inputs, node_def\u001b[38;5;241m.\u001b[39mattr)\n\u001b[0;32m   1982\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 1983\u001b[0m op_desc \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_NewOperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1984\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_def\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1985\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_def\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1986\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node_def\u001b[38;5;241m.\u001b[39mdevice:\n\u001b[0;32m   1987\u001b[0m   pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_SetDevice(op_desc, compat\u001b[38;5;241m.\u001b[39mas_str(node_def\u001b[38;5;241m.\u001b[39mdevice))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# After the training above, it seems that 0.001 is a good learning rate. Let's use it.\n",
    "# Create the model again and perform training with more data.\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    model0 = create_model0(trainable=False)\n",
    "    model0.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history0 = model0.fit(\n",
    "  train_data.repeat(), # is repeat neccessary here?\n",
    "  steps_per_epoch=round(0.25 * len(train_data)),\n",
    "  epochs=5,\n",
    "  validation_data=test_data,\n",
    "  validation_steps=round(0.5 * len(test_data)),\n",
    ")\n",
    "\n",
    "pd.DataFrame(history0.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.dropout.Dropout object at 0x00000214F2E6C910>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.dropout.Dropout object at 0x00000214F2E55F70>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.dropout.Dropout object at 0x00000214F2E90550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.dropout.Dropout object at 0x00000214F2F45F70>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.dropout.Dropout object at 0x00000214F3FE2A30>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.dropout.Dropout object at 0x00000214F2F96CD0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses while saving (showing 5 of 165). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint/distilbert-base-uncased-0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint/distilbert-base-uncased-0\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"checkpoint/distilbert-base-uncased-0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
